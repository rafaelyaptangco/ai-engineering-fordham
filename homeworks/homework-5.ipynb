{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
        "\n",
        "### ðŸ“˜ **Class**: AI Engineering\n",
        "\n",
        "### ðŸ“‹ **Homework 5**: RAG System for Fordham University\n",
        "\n",
        "### ðŸ“… **Due Date**: Day of Lecture 7, 11:59 PM\n",
        "\n",
        "### Difficulty: â˜…â˜…â˜…â˜…â˜†\n",
        "\n",
        "\n",
        "**Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this homework, you'll complete the RAG (Retrieval Augmented Generation) system you started building in Lecture 5. You will build an end-to-end pipeline that can answer questions about Fordham University using real data scraped from the Fordham website.\n",
        "\n",
        "This is an open-ended assignment â€” there is no single right implementation, and you're encouraged to experiment with chunking strategies, embedding models, prompt design, and retrieval parameters to improve your system. **I will grade your system by testing it with specific questions that I know the answer to.**\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "- You may use ChatGPT, Claude, documentation, Stack Overflow, etc. When using external resources, briefly cite them in a comment.\n",
        "- Your submission must include **pre-computed embeddings** and any other artifacts needed so that I can run your RAG system without recomputing anything expensive. Share it with us in a way that makes sense.\n",
        "- Run all cells before submitting to ensure they work.\n",
        "\n",
        "**Submission:**\n",
        "1. Create a branch called `homework-5`\n",
        "2. Commit and push your work (notebook + Streamlit app + saved embeddings/artifacts in `temp/`)\n",
        "3. Create a PR and merge to main\n",
        "4. Submit the `.ipynb` file on Blackboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 1: Load and Chunk the Fordham Website Data\n",
        "\n",
        "In `data/fordham-website.zip` you'll find **~9,500 Markdown files** scraped from Fordham's website. Each file is one page â€” admissions info, program descriptions, faculty pages, financial aid, campus life, and more. The first line of every file is the **URL** of the page it was scraped from. The rest is the page content in Markdown.\n",
        "\n",
        "Think about: chunk size, what to split on (paragraphs, headers, fixed length, etc.), whether chunks should overlap, and how to track which page each chunk came from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9560,\n",
              " [{'page_name': 'Index',\n",
              "   'content': 'https://www.fordham.edu/\\n\\n## Doing Good That Becomes Greater As The Jesuit University of New York\\n\\nWeâ€™re located in New York Cityâ€”driven by our Jesuit values and tackling todayâ€™s most pressing issues at the center of the world stage.\\n\\n## We Are Leaders, Dreamers, Achievers, And Doers\\n\\nWith sound hearts, strong minds, and the wisdom to take charge, generations of Rams have found what they have needed to growâ€”the opportunities, connections, and support of this community.\\n\\n## From Winding Elms to Bustling City Blocks\\n\\nWith residential campuses in the Bronx and Manhattan, as well as campuses in Westchester and London, Fordham provides endless opportunities to start working toward your career and building the life you want.\\n\\n\\n## Weâ€™re Drawn to Where Weâ€™re Needed Most\\n\\nExplore how our values come to life: how Fordhamâ€™s students, faculty, and alumni contribute to society and make lives better.\\n\\n**Notice of Nondiscriminatory Policy:**\\n\\nFordham University admits students of any race, color, national and ethnic origin to all the rights, privileges, programs, and activities generally accorded or made available to students at the school. It does not discriminate on the basis of race, color, national and ethnic origin in administration of its educational policies, admissions policies, scholarship and loan programs, and athletic and other school-administered programs.\\n\\nFordham University is an Equal Opportunity Employer committed to the principle of equal opportunity in education and employment in compliance with Title IX of the Education Amendments of 1972, Section 504 of the Rehabilitation Act of 1973, Title VI and Title VII of the Civil Rights Act of 1964, the Age Discrimination Act of 1975, the Americans with Disabilities Act of 1990, the Violence Against Women Act, and other federal, state, and local laws.'},\n",
              "  {'page_name': 'Research',\n",
              "   'content': 'https://www.fordham.edu/research\\n\\nUncovering the Limitless Possibilities of Science\\n\\nThe Fordham Undergraduate Research Journal, or FURJ, is a student-run journal that features high quality, peer-reviewed, original research.\\n\\nThe Graduate School of Arts and Sciences is pleased to support the research efforts of students. Find the right grant for your graduate level research.\\n\\nJoin us for the upcoming Annual Undergraduate Research Symposium.\\n\\nFordham and four of our neighbors in the Bronx have created a new model for scientific research, education, and community engagement.\\n\\nThis beautiful up-state estate was donated to Fordham for field research in the biological sciences.\\n\\nThe Greyston Bakery in Yonkers, New York, has a management philosophy that employees call life-changing. Itâ€™s based on trust, as seen in the open hiring processâ€”no resumes or interviews required. â€¦\\n\\nRead The Full Story Arrow right icon\\n\\nEven as the rate of inflation subsided in 2023, the amount of stress it was causing in the U.S. population actually ticked upâ€”indicating that researchers need to pay more attention â€¦\\n\\nWith online threats on the rise around the world, one Fordham professor is working on a potentially revolutionary way to head them off and stay one step ahead of the â€¦\\n\\nIsaie Dougnon, Ph.D., an associate professor of French and Francophone studies and international humanitarian affairs, has spent the last few months running a research project that hits close to homeâ€” â€¦\\n\\nA new generation of students at the Bronx Jewish History Project is getting help from those with experienceâ€”the groupâ€™s student co-founder and a professional historian. BJHP is a Fordham research â€¦\\n\\nA Fordham graduate studentâ€™s research is impacting policy around food benefits for young people. This fall in Arizona, advocates used a research report from Alexander Meyer, a Fordham student in â€¦\\n\\nA researcher seeks to advance regenerative medicine After graduating from Fordham College at Rose Hill in 2022 with a degree in integrative neuroscience, Diego Perez landed a spot in the â€¦\\n\\nAn Engineering Physics Majors Launches His Career at SpaceX Growing up in Westport, Connecticut, David Adipietro loved working on cars and wanted to pursue a career in automotive engineering, but â€¦\\n\\nFor Emma Phan, a sophomore chemistry major, the summer was a chance to dive into her research project related to ALS, a neurodegenerative disease. With help from recent graduate Beatriz â€¦\\n\\nMore than 30 undergraduates at Fordham College Rose Hill just completed a summer full of research, mentorship, and exploration. The second annual FCRH Summer Research Program, which had its final â€¦\\n\\nThis summer, Fordham received approval for a new major in biochemistry from the New York State Department of Education. The major aims to help students combine biology and chemistry work â€¦'},\n",
              "  {'page_name': 'Ccel',\n",
              "   'content': 'https://www.fordham.edu/ccel\\n\\n# Center for Community Engaged Learning\\n\\n#### Making an Impact - Here, There, and Everywhere\\n\\n17,463+\\nCommunity Members Engaged Annually\\n\\n5,890+\\nStudents in CCEL Courses and Leadership Programs Annually\\n\\n2,300+\\nCommunity Youth Engaged Through Post-Secondary Pathways\\n\\n102+\\nFordham Faculty Engaged Annually\\n\\nThe Fordham Center for Community Engaged Learning (CCEL) mission is to bridge the university with its neighboring communities and global partners through experiential learning, research, and civic engagement. It fosters reciprocal partnerships by connecting faculty, students, and staff with community organizations to integrate academic inquiry with community engagement, advancing justice and solidarity.\\n\\n### Spring 2026 Community Engaged Learning (CEL) Classes\\n\\n\\n## Visit Us\\n\\n**Rose Hill Campus **\\n\\n441 E. Fordham Road\\n\\nMcShane Campus Center, Suite 215\\n\\nBronx, NY 10458\\n\\n**Lincoln Center Campus**\\n\\n140 W. 62nd Street\\n\\nSuite 140 and 140A\\n\\nNew York, NY 10023'}])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Placeholder for your implementation\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "zip_path = Path(\"fordham-website.zip\")\n",
        "\n",
        "def clean_page_name(path_str: str) -> str:\n",
        "    \"\"\"\n",
        "    Turn 'about/index.html' or 'news-events.html' into a clean page name.\n",
        "    \"\"\"\n",
        "    # Take just the file name (last component)\n",
        "    fname = Path(path_str).name\n",
        "    # Strip extension\n",
        "    stem = Path(fname).stem\n",
        "    # Replace separators with spaces and title-case\n",
        "    clean = stem.replace(\"-\", \" \").replace(\"_\", \" \").strip().title()\n",
        "    return clean\n",
        "\n",
        "docs = []\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "    for info in zf.infolist():\n",
        "        # Skip directories\n",
        "        if info.is_dir():\n",
        "            continue\n",
        "        \n",
        "        # Read file bytes and decode as text\n",
        "        content_bytes = zf.read(info.filename)\n",
        "        try:\n",
        "            text = content_bytes.decode(\"utf-8\")\n",
        "        except UnicodeDecodeError:\n",
        "            # Fallback if some file has a different encoding\n",
        "            text = content_bytes.decode(\"latin-1\", errors=\"ignore\")\n",
        "        \n",
        "        page_name = clean_page_name(info.filename)\n",
        "        \n",
        "        docs.append({\n",
        "            \"page_name\": page_name,   # clean page name / fieldname\n",
        "            \"content\": text           # full file content as a string\n",
        "        })\n",
        "\n",
        "len(docs), docs[:3]  # quick sanity check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 52,694 chunks from 9,560 documents\n",
            "Example chunk: {'page_name': 'Index', 'source_url': 'https://www.fordham.edu/', 'chunk_index': 0, 'content': '\\n## Doing Good That Becomes Greater As The Jesuit University of New York\\n\\nWeâ€™re located in New York Cityâ€”driven by our Jesuit values and tackling todayâ€™s most pressing issues at the center of the world stage.\\n\\n## We Are Leaders, Dreamers, Achievers, And Doers\\n\\nWith sound hearts, strong minds, and the wisdom to take charge, generations of Rams have found what they have needed to growâ€”the opportunities, connections, and support of this community.\\n\\n## From Winding Elms to Bustling City Blocks\\n\\nWith residential campuses in the Bronx and Manhattan, as well as campuses in Westchester and London, Fordham provides endless opportunities to start working toward your career and building the life you want.\\n\\n\\n## Weâ€™re Drawn to Where Weâ€™re Needed Most\\n\\nExplore how our values come to life: how Fordhamâ€™s students, faculty, and alumni contribute to society and make lives better.\\n\\n**Notice of Nondiscrimin'}\n"
          ]
        }
      ],
      "source": [
        "def chunk_documents(\n",
        "    docs: list[dict],\n",
        "    chunk_size: int = 900,\n",
        "    overlap: int = 0,\n",
        ") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Split documents into fixed-size character chunks (default 900 chars).\n",
        "    Each chunk keeps metadata so you know which document it came from.\n",
        "\n",
        "    Args:\n",
        "        docs: List of dicts with \"page_name\" and \"content\" keys\n",
        "        chunk_size: Target number of characters per chunk\n",
        "        overlap: Number of characters to overlap between chunks (0 = no overlap)\n",
        "\n",
        "    Returns:\n",
        "        List of chunk dicts with page_name, source_url, chunk_index, content\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    chunk_id = 0\n",
        "\n",
        "    for doc in docs:\n",
        "        page_name = doc[\"page_name\"]\n",
        "        text = doc[\"content\"]\n",
        "\n",
        "        # First line is the URL; rest is content\n",
        "        lines = text.strip().split(\"\\n\")\n",
        "        source_url = lines[0].strip() if lines else \"\"\n",
        "        body = \"\\n\".join(lines[1:]) if len(lines) > 1 else \"\"\n",
        "\n",
        "        i = 0\n",
        "        chunk_index = 0\n",
        "\n",
        "        while i < len(body):\n",
        "            chunk_text = body[i: i + chunk_size]\n",
        "            chunk_dict = {\n",
        "                \"page_name\": page_name,\n",
        "                \"source_url\": source_url,\n",
        "                \"chunk_index\": chunk_index,\n",
        "                \"content\": chunk_text,\n",
        "            }\n",
        "            chunks.append(chunk_dict)\n",
        "            chunk_index += 1\n",
        "            if overlap > 0:\n",
        "                i += chunk_size - overlap\n",
        "            else:\n",
        "                i += chunk_size\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Run chunking on docs (from cell above)\n",
        "chunks = chunk_documents(docs)\n",
        "print(f\"Created {len(chunks):,} chunks from {len(docs):,} documents\")\n",
        "print(f\"Example chunk: {chunks[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2: Embed the Chunks\n",
        "\n",
        "Turn each chunk into a vector so you can search over them. You can use a local model or an API model â€” your choice.\n",
        "\n",
        "Once you've created your embeddings, **save them somewhere** so you (and I) don't have to redo this step. Save the chunk metadata too (text, source URL, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded existing embeddings from chunk_embeddings.npy with shape (52694, 1536)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure helpers is on path (run notebook from lectures/ or project root)\n",
        "_lectures = Path.cwd() / \"lectures\"\n",
        "if (_lectures / \"helpers.py\").exists():\n",
        "    sys.path.insert(0, str(_lectures))\n",
        "elif not (Path.cwd() / \"helpers.py\").exists():\n",
        "    sys.path.insert(0, \".\")\n",
        "\n",
        "from helpers import get_local_model, batch_embed_local, batch_embed_openai, batch_cosine_similarity\n",
        "from dotenv import load_dotenv\n",
        "import numpy as np\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# \"local\" = Hugging Face (default) | \"openai\" = OpenAI API\n",
        "EMBED_MODEL_TYPE = \"openai\"\n",
        "\n",
        "LOCAL_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
        "OPENAI_MODEL_NAME = \"text-embedding-3-small\"\n",
        "\n",
        "\n",
        "def get_embedding_model(model_type: str = EMBED_MODEL_TYPE):\n",
        "    \"\"\"Load the embedding model. Use same model at search time.\"\"\"\n",
        "    if model_type == \"local\":\n",
        "        return get_local_model(LOCAL_MODEL_NAME)\n",
        "    if model_type == \"openai\":\n",
        "        return None  # API handles calls; no model object\n",
        "    raise ValueError(f\"model_type must be 'local' or 'openai', got {model_type}\")\n",
        "\n",
        "\n",
        "def _truncate_for_openai(text: str, max_chars: int = 8000) -> str:\n",
        "    \"\"\"Simple safeguard: trim very long chunks before sending to OpenAI.\"\"\"\n",
        "    if len(text) <= max_chars:\n",
        "        return text\n",
        "    return text[:max_chars]\n",
        "\n",
        "\n",
        "def embed_texts(texts: list[str], model_type: str = EMBED_MODEL_TYPE, show_progress: bool = True) -> np.ndarray:\n",
        "    \"\"\"Embed a list of texts. Returns (n_texts, dim) numpy array.\"\"\"\n",
        "    if model_type == \"local\":\n",
        "        return batch_embed_local(texts, model_name=LOCAL_MODEL_NAME, show_progress=show_progress)\n",
        "    if model_type == \"openai\":\n",
        "        safe_texts = [_truncate_for_openai(t) for t in texts]\n",
        "        return batch_embed_openai(safe_texts, model=OPENAI_MODEL_NAME, batch_size=50, verbose=show_progress)\n",
        "    raise ValueError(f\"model_type must be 'local' or 'openai', got {model_type}\")\n",
        "\n",
        "\n",
        "# Set to True to only embed 100 chunks for a quick test\n",
        "TEST_MODE = False\n",
        "embeddings_path = Path(\"chunk_embeddings.npy\")\n",
        "\n",
        "if embeddings_path.exists():\n",
        "    # Load previously computed embeddings to avoid re-embedding\n",
        "    chunk_embeddings = np.load(embeddings_path)\n",
        "    n_chunks = chunk_embeddings.shape[0]\n",
        "    chunks_to_embed = chunks[:n_chunks]\n",
        "    print(f\"Loaded existing embeddings from {embeddings_path} with shape {chunk_embeddings.shape}\")\n",
        "else:\n",
        "    # Compute embeddings (optionally in TEST_MODE) and save them\n",
        "    n_chunks = 100 if TEST_MODE else len(chunks)\n",
        "    chunks_to_embed = chunks[:n_chunks]\n",
        "\n",
        "    texts = [c[\"content\"] for c in chunks_to_embed]\n",
        "    chunk_embeddings = embed_texts(texts, model_type=EMBED_MODEL_TYPE)\n",
        "    print(f\"Embedded {len(chunks_to_embed):,} chunks â†’ shape {chunk_embeddings.shape}\")\n",
        "\n",
        "    # Save embeddings so you don't redo this step\n",
        "    np.save(embeddings_path, chunk_embeddings)\n",
        "    print(f\"Saved embeddings to {embeddings_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 3: Retrieve\n",
        "\n",
        "Build the **R** in RAG. Write a function that takes a question and returns the most relevant chunks. You can use semantic search, BM25, hybrid â€” whatever you think works best.\n",
        "\n",
        "Test it on a few questions and eyeball whether the results make sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "\n",
        "def retrieve_chunks(\n",
        "    question: str,\n",
        "    k: int = 5,\n",
        "    model_type: str = EMBED_MODEL_TYPE,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Retrieve the top-k most relevant chunks for a question.\n",
        "\n",
        "    Args:\n",
        "        question: User question in plain text\n",
        "        k: Number of chunks to return\n",
        "        model_type: \"local\" or \"openai\" (must match how `chunk_embeddings` were created)\n",
        "\n",
        "    Returns:\n",
        "        List of chunk dicts augmented with rank and similarity score\n",
        "    \"\"\"\n",
        "    # 1. Embed the question using the same model type\n",
        "    if model_type == \"local\":\n",
        "        model = get_embedding_model(\"local\")\n",
        "        query_emb = model.encode(question, convert_to_numpy=True)\n",
        "    elif model_type == \"openai\":\n",
        "        q_text = _truncate_for_openai(question)\n",
        "        q_embs = batch_embed_openai([q_text], model=OPENAI_MODEL_NAME, batch_size=1, verbose=False)\n",
        "        query_emb = q_embs[0]\n",
        "    else:\n",
        "        raise ValueError(\"model_type must be 'local' or 'openai'\")\n",
        "\n",
        "    # 2. Compute cosine similarity against all chunk embeddings\n",
        "    scores = batch_cosine_similarity(query_emb, chunk_embeddings)\n",
        "\n",
        "    # 3. Get top-k indices\n",
        "    top_idx = np.argsort(-scores)[:k]\n",
        "\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for rank, idx in enumerate(top_idx, start=1):\n",
        "        chunk = chunks_to_embed[idx]\n",
        "        results.append(\n",
        "            {\n",
        "                \"rank\": rank,\n",
        "                \"score\": float(scores[idx]),\n",
        "                **chunk,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Quick sanity check\n",
        "# sample_question = \"How do I apply for financial aid?\"\n",
        "# retrieved = retrieve_chunks(sample_question, k=3, model_type=EMBED_MODEL_TYPE)\n",
        "# for r in retrieved:\n",
        "#     print(f\"Rank {r['rank']} | score={r['score']:.4f} | page={r['page_name']}\")\n",
        "#     print(r[\"content\"][:200].replace(\"\\n\", \" \"), \"...\\n\")\n",
        "#     print(\"-\" * 80)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 4: Generate\n",
        "\n",
        "Build the **G** in RAG. Write a function that takes a question and the retrieved chunks, builds a prompt, and calls an LLM to generate an answer.\n",
        "\n",
        "Think about: how to structure the prompt, what the LLM should do when the context doesn't contain the answer, and which model to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "import litellm\n",
        "\n",
        "def generate_answer(\n",
        "    question: str,\n",
        "    retrieved_chunks: list[dict],\n",
        "    model: str = \"gpt-4o-mini\",\n",
        ") -> str:\n",
        "    \"\"\"Build a prompt from question + chunks, call LLM, return answer.\"\"\"\n",
        "    context_parts = []\n",
        "    for c in retrieved_chunks:\n",
        "        context_parts.append(f\"[Source: {c.get('page_name', 'Unknown')}]\\n{c['content']}\")\n",
        "    context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
        "\n",
        "    system = (\n",
        "        \"You are a helpful assistant that answers questions about Fordham University \"\n",
        "        \"using only the provided context. If the context does not contain the answer, \"\n",
        "        \"say so clearly. Do not make up information.\"\n",
        "    )\n",
        "    user = f\"Context:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
        "\n",
        "    response = litellm.completion(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": user},\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 5: Wire it Together\n",
        "\n",
        "Combine the previous steps into a single `rag(question)` function. Question in, answer out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apostolos Filippas is an assistant professor at Fordham University's Gabelli School of Business. He is the Christopher Blake Distinguished Research Scholar in Business and specializes in Information, Technology, and Operations. He holds a Ph.D. in Business Administration from the NYU Stern School of Business and is an economist focusing on market design and the economics of technology, particularly in relation to online platforms. His teaching includes courses on Web Analytics and E-Commerce. Filippas also conducts research on topics such as reputation and pricing systems in online marketplaces and the economic implications of the \"sharing economy.\"\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "def rag(question: str, k: int = 5, model: str = \"gpt-4o-mini\") -> str:\n",
        "    \"\"\"User's question flows in â†’ retrieve â†’ generate_answer. Question in, answer out.\"\"\"\n",
        "    chunks = retrieve_chunks(question, k=k, model_type=EMBED_MODEL_TYPE)\n",
        "    return generate_answer(question, chunks, model=model)\n",
        "\n",
        "\n",
        "# Example: question is the input; it flows to retrieve, then to generate_answer\n",
        "user_question = input(\"Enter your question about Fordham University: \")\n",
        "answer = rag(user_question)\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: What programs does the Gabelli School of Business offer?\n",
            "A: The Gabelli School of Business offers the following graduate business programs:\n",
            "\n",
            "1. Full-time cohort M.B.A.\n",
            "2. Professional M.B.A. (including part-time)\n",
            "3. Executive M.B.A.\n",
            "\n",
            "Additionally, it provides undergraduate business degrees.\n",
            "--------------------------------------------------------------------------------\n",
            "Q: How do I apply for financial aid at Fordham?\n",
            "A: To apply for financial aid at Fordham University, follow these steps:\n",
            "\n",
            "1. Complete the Free Application for Federal Student Aid (FAFSA) using Fordhamâ€™s school code: 002722. Sign your FAFSA application electronically using your Federal Student Aid (FSA) ID.\n",
            "2. If you do not have an FSA ID, you will need to create one when logging in to the FAFSA.\n",
            "3. Claim your Fordham ID, which will give you access to the financial aid channel of your student portal.\n",
            "4. Complete the Direct Loan Request Form, which can be done electronically in your student portal once you are admitted. \n",
            "\n",
            "Make sure to also include your correct social security number (SSN) in your application for admission to ensure that your FAFSA can be properly downloaded by Fordham.\n",
            "--------------------------------------------------------------------------------\n",
            "Q: What is the tuition for undergraduate students?\n",
            "A: The tuition for undergraduate students at Fordham University for the 2025-2026 academic year is $65,920 per year, which breaks down to $32,960 per semester for full-time students. For part-time students, the tuition rate is $2,197 per credit.\n",
            "--------------------------------------------------------------------------------\n",
            "Q: Tell me about Fordham's campus locations.\n",
            "A: Fordham University has two campuses located in New York City: \n",
            "\n",
            "1. **Rose Hill Campus** - Situated in the Bronx, this is the original campus of Fordham University. It features a traditional college environment with green lawns, trees, large residence halls, and sports facilities.\n",
            "\n",
            "2. **Lincoln Center Campus** - Located in the heart of Manhattan, this campus offers a vibrant urban experience.\n",
            "\n",
            "The two campuses are about eight miles apart and are connected by an intercampus shuttle service known as the Ram Van. Each campus has its own distinct personality while sharing most academic departments, though each specializes in certain fields.\n",
            "--------------------------------------------------------------------------------\n",
            "Q: What research opportunities are available for students?\n",
            "A: Fordham University offers a variety of research opportunities for students, particularly in STEM fields and for pre-health students. \n",
            "\n",
            "1. **Undergraduate Research in Chemistry & Biochemistry**: Students can engage in research during the school year and summer, working in active research laboratories under the guidance of faculty mentors. Opportunities include projects in analytical chemistry, chemical evolution, and environmental science, among others.\n",
            "\n",
            "2. **Pre-Health Research Opportunities**: Pre-health students can participate in research projects, gaining exposure to methodologies and the scientific inquiry process. They may also get involved in research at the Louis Calder Center and other institutions like Memorial Sloan Kettering Cancer Center and Albert Einstein College of Medicine.\n",
            "\n",
            "3. **General Undergraduate Research and Internships**: Fordham College at Rose Hill offers diverse research opportunities across various disciplines. Students can present their work at conferences, receive mentoring, and engage in projects that enhance their analytical and communication skills.\n",
            "\n",
            "4. **Summer Research Programs**: During the summer, students typically work in labs, collaborating on research projects with faculty members. This experience is valuable for both personal and professional development.\n",
            "\n",
            "Overall, Fordham encourages students to get involved in research to strengthen their resumes and professional school applications while expanding their understanding of their fields.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate your RAG system\n",
        "\n",
        "demo_questions = [\n",
        "    \"What programs does the Gabelli School of Business offer?\",\n",
        "    \"How do I apply for financial aid at Fordham?\",\n",
        "    \"What is the tuition for undergraduate students?\",\n",
        "    \"Tell me about Fordham's campus locations.\",\n",
        "    \"What research opportunities are available for students?\",\n",
        "]\n",
        "\n",
        "for q in demo_questions:\n",
        "    print(f\"Q: {q}\")\n",
        "    answer = rag(q)\n",
        "    print(f\"A: {answer}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 6: Evaluate Your RAG System\n",
        "\n",
        "A working RAG system is great â€” but how do you know it's actually *good*? You can't improve what you can't measure. In this step you'll build an evaluation framework using concepts from Lecture 6.\n",
        "\n",
        "There are two things to evaluate in a RAG system:\n",
        "- **Retrieval quality**: Are you finding the right chunks?\n",
        "- **Answer quality**: Is the generated answer correct and grounded in the context?\n",
        "\n",
        "### Build a test set\n",
        "\n",
        "Create a test set of at least **10 question-answer pairs**. For each pair, provide the question and the expected answer (look it up in the data). Cover a range of question types â€” factual, procedural, about specific programs, etc.\n",
        "\n",
        "### Evaluate retrieval\n",
        "\n",
        "For each question, check whether the retrieved chunks actually contain relevant information. You can do this manually or automatically (e.g., use an LLM to judge relevance). Compute **context relevance** â€” the fraction of retrieved chunks that are actually useful.\n",
        "\n",
        "### Evaluate answers with LLM-as-judge\n",
        "\n",
        "Use an LLM to evaluate your system's answers on two dimensions:\n",
        "\n",
        "1. **Faithfulness**: Does the answer only use information from the retrieved context? (No hallucination)\n",
        "2. **Correctness**: Is the answer factually correct compared to the expected answer?\n",
        "\n",
        "Use **structured outputs** (Pydantic) to get consistent scores from the judge. A starting schema is provided below â€” feel free to modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class RAGEvaluation(BaseModel):\n",
        "    faithfulness_score: int = Field(\n",
        "        ..., ge=1, le=5,\n",
        "        description=\"1=completely hallucinated, 5=fully grounded in context\"\n",
        "    )\n",
        "    faithfulness_reasoning: str = Field(\n",
        "        ..., description=\"Brief explanation of the faithfulness score\"\n",
        "    )\n",
        "    correctness_score: int = Field(\n",
        "        ..., ge=1, le=5,\n",
        "        description=\"1=completely wrong, 5=fully correct and complete\"\n",
        "    )\n",
        "    correctness_reasoning: str = Field(\n",
        "        ..., description=\"Brief explanation of the correctness score\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Example 1 =====\n",
            "Question: What programs does the Gabelli School of Business offer?\n",
            "System answer: The Gabelli School of Business offers three variants of the MBA program: \n",
            "\n",
            "1. Full-time cohort M.B.A.\n",
            "2. Professional M.B.A. (including part-time options)\n",
            "3. Executive M.B.A.\n",
            "\n",
            "Additionally, they provide graduate business degrees and undergraduate business degrees, focusing on leveraging business for positive change.\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 5 | Correctness: 5\n",
            "-\n",
            "===== Example 2 =====\n",
            "Question: How do I apply for financial aid at Fordham?\n",
            "System answer: To apply for financial aid at Fordham University, you need to follow these steps:\n",
            "\n",
            "1. Complete the Free Application for Federal Student Aid (FAFSA) using Fordhamâ€™s school code: 002722.\n",
            "2. Sign your FAFSA application electronically using your Federal Student Aid (FSA) ID. If you do not have an FSA ID, you will be prompted to create one while logging in.\n",
            "3. Claim your Fordham ID to gain access to th...\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 5 | Correctness: 4\n",
            "-\n",
            "===== Example 3 =====\n",
            "Question: What is the tuition for undergraduate students at Fordham?\n",
            "System answer: The provided context does not contain information about the tuition for undergraduate students at Fordham University.\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 5 | Correctness: 4\n",
            "-\n",
            "===== Example 4 =====\n",
            "Question: Where are Fordham's main campuses located?\n",
            "System answer: Fordham University has two main campuses located in New York City: the Rose Hill campus in the Bronx and the Lincoln Center campus in Manhattan.\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 5 | Correctness: 4\n",
            "-\n",
            "===== Example 5 =====\n",
            "Question: What research opportunities are available for students at Fordham?\n",
            "System answer: At Fordham, students have access to various research opportunities, including:\n",
            "\n",
            "1. **Independent Research**: Students can pursue independent research projects under the guidance of faculty at both the Rose Hill and Lincoln Center campuses.\n",
            "\n",
            "2. **Undergraduate Research Grants**: Funding is available for undergraduate research projects, with specific grant opportunities listed on their respective we...\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 4 | Correctness: 4\n",
            "-\n",
            "===== Example 6 =====\n",
            "Question: How do I apply as an international undergraduate student to Fordham?\n",
            "System answer: There is no separate application for international students at Fordham University. You can apply as an international undergraduate student by answering the application questions, which will help Fordham determine your international student status. You need to submit the required application components, which include an essay. For specific requirements or additional questions, you may contact the u...\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 4 | Correctness: 3\n",
            "-\n",
            "===== Example 7 =====\n",
            "Question: What housing options are available for first-year students?\n",
            "System answer: First-year students at Fordham University have several housing options available on the Rose Hill campus. They can choose from a variety of residence halls, each with its own unique architecture and ambience. Some specific options mentioned include:\n",
            "\n",
            "- **Alumni Court South**: Accommodates mostly first-year students, featuring double and triple rooms, common bathrooms, and amenities such as game ro...\n",
            "Context relevance (fraction of useful chunks): 0.80\n",
            "Faithfulness: 4 | Correctness: 3\n",
            "-\n",
            "===== Example 8 =====\n",
            "Question: Does Fordham offer study abroad programs?\n",
            "System answer: Yes, Fordham offers study abroad programs, including Fordham Semester Programs, exchange programs at universities worldwide, and short-term programs during the winter intersession, spring, and summer.\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 5 | Correctness: 4\n",
            "-\n",
            "===== Example 9 =====\n",
            "Question: What scholarships are available to incoming undergraduates?\n",
            "System answer: Incoming undergraduate students at Fordham University may be considered for all Fordham Scholarships. The application for admission also serves as the application for these awards. The aid comes from Fordham's own resources and is available to full-time traditional undergraduate students to supplement aid from other sources.\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 4 | Correctness: 3\n",
            "-\n",
            "===== Example 10 =====\n",
            "Question: What is Fordham's mission as a Jesuit university?\n",
            "System answer: Fordham University's mission as a Jesuit university is to commit to the discovery of wisdom and the transmission of learning through research and high-quality undergraduate, graduate, and professional education. Guided by its Catholic and Jesuit traditions, Fordham fosters the intellectual, moral, and religious development of its students and prepares them for leadership in a global society. This ...\n",
            "Context relevance (fraction of useful chunks): 1.00\n",
            "Faithfulness: 4 | Correctness: 3\n",
            "-\n",
            "\n",
            "===== Aggregate Evaluation =====\n",
            "Average context relevance: 0.98\n",
            "Average faithfulness score: 4.50 / 5\n",
            "Average correctness score: 3.70 / 5\n"
          ]
        }
      ],
      "source": [
        "# Build a small evaluation harness for the RAG system\n",
        "\n",
        "import re\n",
        "import json\n",
        "from statistics import mean\n",
        "from typing import List, Dict\n",
        "\n",
        "# --- 1. Test set of questionâ€“answer pairs ---\n",
        "# These answers are short \"gold\" references the judge will compare against.\n",
        "TEST_SET: List[Dict[str, str]] = [\n",
        "    {\n",
        "        \"question\": \"What programs does the Gabelli School of Business offer?\",\n",
        "        \"expected_answer\": \"Gabelli offers undergraduate business degrees and several MBA programs, including full-time cohort, professional/part-time, and executive MBAs.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I apply for financial aid at Fordham?\",\n",
        "        \"expected_answer\": \"Complete the FAFSA using Fordham's school code and follow the steps in the student portal and financial aid pages.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the tuition for undergraduate students at Fordham?\",\n",
        "        \"expected_answer\": \"Undergraduate tuition is specified on Fordham's tuition and fees page for the current academic year.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Where are Fordham's main campuses located?\",\n",
        "        \"expected_answer\": \"Fordham's main campuses are Rose Hill in the Bronx and Lincoln Center in Manhattan, with additional locations such as Westchester and London.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What research opportunities are available for students at Fordham?\",\n",
        "        \"expected_answer\": \"Fordham offers undergraduate and graduate research opportunities, including working with faculty, research centers, and funded projects.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I apply as an international undergraduate student to Fordham?\",\n",
        "        \"expected_answer\": \"International applicants submit the application, transcripts, English proficiency scores, and other required documents listed on the international admission page.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What housing options are available for first-year students?\",\n",
        "        \"expected_answer\": \"Fordham provides on-campus residence halls for first-year students, primarily at Rose Hill and Lincoln Center.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Does Fordham offer study abroad programs?\",\n",
        "        \"expected_answer\": \"Fordham offers study abroad programs and has a campus in London along with partnerships in other locations.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What scholarships are available to incoming undergraduates?\",\n",
        "        \"expected_answer\": \"Fordham offers merit-based and need-based scholarships described on its undergraduate financial aid and scholarships pages.\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is Fordham's mission as a Jesuit university?\",\n",
        "        \"expected_answer\": \"Fordham's mission emphasizes Jesuit values, educating students for justice, leadership, and service in New York City and beyond.\",\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "# --- 2. Simple retrieval-quality metric (context relevance) ---\n",
        "\n",
        "_STOPWORDS = {\n",
        "    \"what\",\n",
        "    \"how\",\n",
        "    \"is\",\n",
        "    \"are\",\n",
        "    \"the\",\n",
        "    \"a\",\n",
        "    \"an\",\n",
        "    \"of\",\n",
        "    \"for\",\n",
        "    \"at\",\n",
        "    \"to\",\n",
        "    \"in\",\n",
        "    \"on\",\n",
        "    \"about\",\n",
        "    \"does\",\n",
        "    \"do\",\n",
        "    \"me\",\n",
        "    \"tell\",\n",
        "    \"students\",\n",
        "    \"student\",\n",
        "    \"fordham\",\n",
        "    \"university\",\n",
        "}\n",
        "\n",
        "\n",
        "def _extract_keywords(text: str) -> List[str]:\n",
        "    \"\"\"Very simple keyword extractor for retrieval evaluation.\"\"\"\n",
        "    tokens = re.findall(r\"[a-zA-Z]+\", text.lower())\n",
        "    return [t for t in tokens if t not in _STOPWORDS and len(t) > 2]\n",
        "\n",
        "\n",
        "def evaluate_retrieval_context_relevance(question: str, retrieved_chunks: List[Dict]) -> float:\n",
        "    \"\"\"Heuristic: fraction of retrieved chunks containing any question keyword.\n",
        "\n",
        "    This is a cheap, deterministic proxy for context relevance. A more\n",
        "    advanced version could use an LLM-as-judge, but this keeps evaluation\n",
        "    fast and reproducible.\n",
        "    \"\"\"\n",
        "    keywords = _extract_keywords(question)\n",
        "    if not retrieved_chunks or not keywords:\n",
        "        return 0.0\n",
        "\n",
        "    relevant = 0\n",
        "    for c in retrieved_chunks:\n",
        "        content = c.get(\"content\", \"\").lower()\n",
        "        if any(kw in content for kw in keywords):\n",
        "            relevant += 1\n",
        "    return relevant / len(retrieved_chunks)\n",
        "\n",
        "\n",
        "# --- 3. LLM-as-judge for answer quality (faithfulness + correctness) ---\n",
        "\n",
        "\n",
        "def judge_answer_with_llm(\n",
        "    question: str,\n",
        "    expected_answer: str,\n",
        "    system_answer: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        ") -> RAGEvaluation:\n",
        "    \"\"\"Use an LLM to score faithfulness and correctness via RAGEvaluation.\n",
        "\n",
        "    The model is instructed to return a JSON object that we validate with\n",
        "    the RAGEvaluation Pydantic schema.\n",
        "    \"\"\"\n",
        "    system_prompt = (\n",
        "        \"You are an evaluator for a RAG system. You will receive a user question, \"\n",
        "        \"the system's answer, and a reference expected answer. \"\n",
        "        \"Score faithfulness (grounding in the system answer's context is approximated \"\n",
        "        \"by how cautious and non-hallucinatory it is) and correctness (alignment with \"\n",
        "        \"the reference answer) on a 1â€“5 scale, and respond ONLY with a JSON object \"\n",
        "        \"matching the RAGEvaluation schema.\"\n",
        "    )\n",
        "\n",
        "    user_prompt = {\n",
        "        \"question\": question,\n",
        "        \"system_answer\": system_answer,\n",
        "        \"expected_answer\": expected_answer,\n",
        "    }\n",
        "\n",
        "    resp = litellm.completion(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": json.dumps(user_prompt)},\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "    )\n",
        "\n",
        "    raw = resp.choices[0].message.content\n",
        "    data = json.loads(raw)\n",
        "\n",
        "    # Map model keys into the schema fields, allowing for \"faithfulness\"/\"correctness\" short keys\n",
        "    faith_score = data.get(\"faithfulness_score\", data.get(\"faithfulness\"))\n",
        "    corr_score = data.get(\"correctness_score\", data.get(\"correctness\"))\n",
        "\n",
        "    eval_data = {\n",
        "        \"faithfulness_score\": faith_score,\n",
        "        \"correctness_score\": corr_score,\n",
        "        \"faithfulness_reasoning\": data.get(\n",
        "            \"faithfulness_reasoning\",\n",
        "            f\"Model rated faithfulness as {faith_score}.\",\n",
        "        ),\n",
        "        \"correctness_reasoning\": data.get(\n",
        "            \"correctness_reasoning\",\n",
        "            f\"Model rated correctness as {corr_score}.\",\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    return RAGEvaluation(**eval_data)\n",
        "\n",
        "\n",
        "# --- 4. Run evaluation over the test set and summarize ---\n",
        "\n",
        "retrieval_scores: List[float] = []\n",
        "faithfulness_scores: List[int] = []\n",
        "correctness_scores: List[int] = []\n",
        "\n",
        "for i, item in enumerate(TEST_SET, start=1):\n",
        "    q = item[\"question\"]\n",
        "    gold = item[\"expected_answer\"]\n",
        "\n",
        "    # Retrieve context\n",
        "    retrieved = retrieve_chunks(q, k=5, model_type=EMBED_MODEL_TYPE)\n",
        "    ctx_rel = evaluate_retrieval_context_relevance(q, retrieved)\n",
        "    retrieval_scores.append(ctx_rel)\n",
        "\n",
        "    # Generate system answer using our RAG pipeline\n",
        "    system_answer = generate_answer(q, retrieved, model=\"gpt-4o-mini\")\n",
        "\n",
        "    # Judge with LLM\n",
        "    eval_result = judge_answer_with_llm(q, gold, system_answer, model=\"gpt-4o-mini\")\n",
        "    faithfulness_scores.append(eval_result.faithfulness_score)\n",
        "    correctness_scores.append(eval_result.correctness_score)\n",
        "\n",
        "    print(f\"===== Example {i} =====\")\n",
        "    print(f\"Question: {q}\")\n",
        "    print(f\"System answer: {system_answer[:400]}{'...' if len(system_answer) > 400 else ''}\")\n",
        "    print(f\"Context relevance (fraction of useful chunks): {ctx_rel:.2f}\")\n",
        "    print(\n",
        "        f\"Faithfulness: {eval_result.faithfulness_score} | \"\n",
        "        f\"Correctness: {eval_result.correctness_score}\"\n",
        "    )\n",
        "    print(\"-\")\n",
        "\n",
        "print(\"\\n===== Aggregate Evaluation =====\")\n",
        "print(f\"Average context relevance: {mean(retrieval_scores):.2f}\")\n",
        "print(f\"Average faithfulness score: {mean(faithfulness_scores):.2f} / 5\")\n",
        "print(f\"Average correctness score: {mean(correctness_scores):.2f} / 5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 7: Build a Streamlit App\n",
        "\n",
        "Your RAG system lives inside a notebook â€” that's great for development, but nobody is going to use a Jupyter notebook to ask questions about Fordham. Turn it into a web app using [Streamlit](https://docs.streamlit.io/).\n",
        "\n",
        "Create a `.py` file (e.g., `scripts/fordham_rag_app.py`) that:\n",
        "1. Lets the user type a question about Fordham\n",
        "2. Runs your RAG pipeline\n",
        "3. Displays the answer and the source pages used\n",
        "\n",
        "**Getting started:**\n",
        "- Install: `uv pip install streamlit`\n",
        "- Run: `streamlit run scripts/fordham_rag_app.py`\n",
        "\n",
        "**Tip**: Use `@st.cache_resource` to avoid reloading embeddings on every interaction.\n",
        "\n",
        "**Include a screenshot of your working app below.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](RAG-streamlit-app.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 8: How to Run Your System\n",
        "\n",
        "Fill in the details below so that I can run and test your RAG system.\n",
        "\n",
        "| Item | Your Answer |\n",
        "|------|-------------|\n",
        "| **Embedding model used** | |\n",
        "| **LLM used for generation** | |\n",
        "| **LLM used for evaluation (judge)** | |\n",
        "| **Saved artifacts** | (list the files â€” e.g., `embeddings.npy`, `chunks.json`) |\n",
        "| **How to start the Streamlit app** | (e.g., `streamlit run scripts/fordham_rag_app.py`) |\n",
        "| **Any API keys or env vars needed** | (e.g., `OPENAI_API_KEY` in `.env`) |\n",
        "| **Anything else I should know** | |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Bonus: Experiment and Improve\n",
        "\n",
        "Now that you have a working RAG system *and* a way to measure its quality, try to improve it. Use your evaluation framework to measure the impact of changes.\n",
        "\n",
        "Ideas: different chunk sizes, different embedding models, hybrid search, better prompts, reranking, query rewriting. Document what you tried and show before/after evaluation scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Git Submission\n",
        "\n",
        "- [ ] Create a new branch called `homework-5`\n",
        "- [ ] Commit your work (notebook + Streamlit app + saved artifacts in `temp/`)\n",
        "- [ ] Push to GitHub\n",
        "- [ ] Create a Pull Request and merge to main\n",
        "- [ ] Submit the `.ipynb` file on Blackboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (ai-engineering-fordham)",
      "language": "python",
      "name": "ai-engineering-fordham"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
